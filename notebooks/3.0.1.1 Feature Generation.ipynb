{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443ea252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for array manipulations\n",
    "import numpy as np\n",
    "#for image processing\n",
    "import cv2 \n",
    "#for displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "#to display images in this notebook, not in a separate window\n",
    "%matplotlib inline\n",
    "#to access system resources such as directories\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6129ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set this to point to the project root; all paths will be relative to this one\n",
    "project_dir = '/home/lyle/notebooks/maize-disease-detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7e6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_directories(project_dir=project_dir):\n",
    "    \"\"\"Sets up the paths to important direcoties\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    project_dir : string; default is the current working directory\n",
    "        The path to the project root i.e '/home/lyle/tutorials/AI/scikit-learn/maize-disease-detection/'\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    base_dir : string\n",
    "        The project directory path\n",
    "    data_folder : string\n",
    "        The data subfolder path\n",
    "    maize_data_folder : \n",
    "        The path to the subdirectory containing the maize images\n",
    "        \n",
    "    example usage\n",
    "    -------------\n",
    "    base_dir, data_folder, maize_data_folder = set_up_directories()\n",
    "    \"\"\"\n",
    "    \n",
    "    #set our base directory. This should point to the location of the plant-diseases folder\n",
    "    base_dir = project_dir\n",
    "    #set the path to our data folder\n",
    "    data_folder = os.path.join(base_dir, 'data')\n",
    "    #set the path to the maize folder and list the various categories available\n",
    "    maize_data_folder = os.path.join(data_folder, 'maize')\n",
    "\n",
    "    return base_dir, data_folder, maize_data_folder\n",
    "\n",
    "def get_32(disease):\n",
    "    \"\"\"Loads 32 images for a given maize disease\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    disease: string\n",
    "        A string that could be common_rust, healthy, leaf_spot, nothern_leaf_blight\n",
    "    returns\n",
    "    -------\n",
    "    disease_images: list\n",
    "        A list of images for the selected disease\n",
    "    \"\"\"\n",
    "    \n",
    "    #this list will contain the 20 images returned\n",
    "    disease_images = []\n",
    "    #path to the images\n",
    "    disease_images_path = os.path.join(maize_data_folder, disease)\n",
    "    for image_path in os.listdir(disease_images_path):\n",
    "        image_path = os.path.join(disease_images_path, image_path)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        disease_images.append(image)\n",
    "    return disease_images\n",
    "\n",
    "#This function will help us plot 10 images\n",
    "def plot_images(images, title):\n",
    "    \"\"\"Plots 10 images of a particular disease category\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    images: list\n",
    "        List of images(each image is an array)\n",
    "    title: string\n",
    "        Title for each image i.e name of disease\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2,5, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(title)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "#This function allows us to resize images\n",
    "def resize(image, new_size=(600,600)):\n",
    "    \"\"\"Resize the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image to be resized\n",
    "    new_size : tuple\n",
    "        The new image size\n",
    "    returns\n",
    "    -------\n",
    "    resized_image : numpy arra\n",
    "        The resized image\n",
    "    \"\"\"\n",
    "    \n",
    "    resized_image = cv2.resize(image, new_size)\n",
    "    return resized_image\n",
    "\n",
    "#This function generates ORB features\n",
    "def extract_features_orb(image, vector_size=32):\n",
    "    \"\"\"Extracts orb features for the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    returns\n",
    "    -------\n",
    "        orb_decriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feature_generator = cv2.ORB_create()\n",
    "        orb_keypoints = feature_generator.detect(image)\n",
    "        orb_keypoints = orb_keypoints[:32]\n",
    "        orb_keypoints, orb_descriptors = feature_generator.compute(image, orb_keypoints)\n",
    "        orb_descriptors = orb_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if orb_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            orb_descriptors = np.concatenate([orb_descriptors, np.zeros(needed_size - orb_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return orb_descriptors\n",
    "\n",
    "#This function generates KAZE features\n",
    "def extract_features_kaze(image, vector_size=32):\n",
    "    \"\"\"Extracts kaze features for the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    returns\n",
    "    -------\n",
    "        kaze_descriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feature_generator = cv2.KAZE_create()\n",
    "        kaze_keypoints = feature_generator.detect(image)\n",
    "        kaze_keypoints = kaze_keypoints[:32]\n",
    "        kaze_keypoints, kaze_descriptors = feature_generator.compute(image, kaze_keypoints)\n",
    "        kaze_descriptors = kaze_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if kaze_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            kaze_descriptors = np.concatenate([kaze_descriptors, np.zeros(needed_size - kaze_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return kaze_descriptors\n",
    "\n",
    "def extract_hog_features(image, feature_size=4096):\n",
    "    \"\"\"Extracts hog features for the image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    feature_size : int\n",
    "        The number of features to generate\n",
    "    returns\n",
    "    -------\n",
    "        hog_features : numpy array \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    features = hog.compute(common_rust_images[0])\n",
    "    required_features = features[:feature_size].ravel()\n",
    "    return required_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c373c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function generates SIFT features\n",
    "def extract_features_sift(image, vector_size=32):\n",
    "    \"\"\"Extracts sift features for the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    returns\n",
    "    -------\n",
    "        sift_descriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feature_generator = cv2.SIFT_create()\n",
    "        sift_keypoints = feature_generator.detect(image)\n",
    "        sift_keypoints = sift_keypoints[:32]\n",
    "        sift_keypoints, sift_descriptors = feature_generator.compute(image, sift_keypoints)\n",
    "        sift_descriptors = sift_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if sift_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            sift_descriptors = np.concatenate([sift_descriptors, np.zeros(needed_size - sift_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return sift_descriptors\n",
    "\n",
    "#This function generates SURF features\n",
    "def extract_features_surf(image, vector_size=32):\n",
    "    \"\"\"Extracts surf features for the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    returns\n",
    "    -------\n",
    "        surf_descriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initiate FAST detector\n",
    "        star = cv2.xfeatures2d.StarDetector_create()\n",
    "        surf_keypoints = feature_generator.detect(image)\n",
    "        surf_keypoints = surf_keypoints[:32]\n",
    "        surf_keypoints, surf_descriptors = feature_generator.compute(image, surf_keypoints)\n",
    "        surf_descriptors = surf_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if surf_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            sift_descriptors = np.concatenate([surf_descriptors, np.zeros(needed_size - surf_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return surf_descriptors\n",
    "\n",
    "#This function generates SIFT features\n",
    "def extract_features_brief(image, vector_size=32, algorithm=\"star\"):\n",
    "    \"\"\"Extracts features for the given image using BRIEF\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    algorithm : string\n",
    "        The algorithm to use; can be star or fast\n",
    "    returns\n",
    "    -------\n",
    "        brief_descriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        alg = cv2.xfeatures2d.StarDetector_create()\n",
    "        if algorithm == \"fast\":\n",
    "            alg = cv2.FastFeatureDetector_create()\n",
    "        brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "        \n",
    "        kp = alg.detect(image, None)\n",
    "        kp = kp[:32]\n",
    "        kp, des = brief.compute(image, kp)\n",
    "        des = des.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if des.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            des = np.concatenate([des, np.zeros(needed_size - des.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return np.array([])\n",
    "    except AttributeError:\n",
    "        return np.array([])\n",
    "    return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab7b7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directories set up\n",
    "base_dir, data_folder, maize_data_folder = set_up_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197e4737",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_rust_images = get_32('common_rust')\n",
    "healthy_images = get_32('healthy')\n",
    "leaf_spot_images = get_32('leaf_spot')\n",
    "nothern_leaf_blight_images = get_32('nothern_leaf_blight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce0f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_rust_image_orb_features = extract_features_orb(common_rust_images[0])\n",
    "common_rust_image_kaze_features = extract_features_kaze(common_rust_images[0])\n",
    "common_rust_image_hog_features = extract_hog_features(common_rust_images[0])\n",
    "common_rust_image_sift_features = extract_features_sift(common_rust_images[0])\n",
    "common_rust_image_brief_features = extract_features_brief(common_rust_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fbba8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_image_orb_features = extract_features_orb(healthy_images[0])\n",
    "healthy_image_kaze_features = extract_features_kaze(healthy_images[0])\n",
    "healthy_image_hog_features = extract_hog_features(healthy_images[0])\n",
    "healthy_image_brief_features = extract_features_brief(healthy_images[0])\n",
    "healthy_image_sift_features = extract_features_sift(healthy_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec2b96b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_spot_image_orb_features = extract_features_orb(leaf_spot_images[0])\n",
    "leaf_spot_image_kaze_features = extract_features_kaze(leaf_spot_images[0])\n",
    "leaf_spot_image_hog_features = extract_hog_features(leaf_spot_images[0])\n",
    "leaf_spot_image_brief_features = extract_features_brief(leaf_spot_images[0])\n",
    "leaf_spot_image_sift_features = extract_features_sift(leaf_spot_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58bc78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nothern_leaf_blight_image_orb_features = extract_features_orb(nothern_leaf_blight_images[0])\n",
    "nothern_leaf_blight_image_kaze_features = extract_features_kaze(nothern_leaf_blight_images[0])\n",
    "nothern_leaf_blight_image_hog_features = extract_hog_features(nothern_leaf_blight_images[0])\n",
    "nothern_leaf_blight_image_brief_features = extract_features_brief(nothern_leaf_blight_images[0])\n",
    "nothern_leaf_blight_image_sift_features = extract_features_sift(nothern_leaf_blight_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9ad44e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4096)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this example, we generate a sample dataset, using the sample kaze features we just generated\n",
    "#A dataset usually consists of an items features and the corresponding labels\n",
    "#This will be our feature set\n",
    "sample_kaze_features =[]\n",
    "#This will contain our labels\n",
    "sample_kaze_labels = []\n",
    "sample_kaze_features.append(common_rust_image_kaze_features)\n",
    "sample_kaze_labels.append('common_rust')\n",
    "sample_kaze_features.append(healthy_image_kaze_features)\n",
    "sample_kaze_labels.append('healthy')\n",
    "sample_kaze_features.append(leaf_spot_image_kaze_features)\n",
    "sample_kaze_labels.append('leaf_spot')\n",
    "sample_kaze_features.append(nothern_leaf_blight_image_kaze_features)\n",
    "sample_kaze_labels.append('nothern_leaf_blight')\n",
    "sample_kaze_labels = np.array(sample_kaze_labels)\n",
    "sample_kaze_features = np.array(sample_kaze_features)\n",
    "#In our dataset, we have four instances and each instance has 4096 features\n",
    "sample_kaze_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8819e71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have four labels, each label just tells us the disease type\n",
    "sample_kaze_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ed1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we create a sample dataset for the model. X and y are the standard variables used\n",
    "X = sample_kaze_features\n",
    "y = sample_kaze_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c01f2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Scaling is one of the preprocessing steps to enable our models work better\n",
    "X = StandardScaler().fit_transform(X)\n",
    "#We split into a train set and a test set\n",
    "X_train, X_test = train_test_split(X, test_size=0.1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b57a8cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our train data set is of shape (3, 4096)\n",
      "Our test dataset is of shape (1, 4096)\n"
     ]
    }
   ],
   "source": [
    "print(f'Our train data set is of shape {X_train.shape}')\n",
    "print(f'Our test dataset is of shape {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88c77077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#We encode our labels into numerical values since that is the kind of dataset that models work with\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "#We then split into a train and test set\n",
    "y_train, y_test = train_test_split(y, test_size=0.1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "737b8770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (1,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36b1878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef08f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will contain all our images\n",
    "all_images = []\n",
    "#This will contain all our labels\n",
    "all_labels = []\n",
    "labels = ['common_rust', 'healthy', 'leaf_spot', 'nothern_leaf_blight']\n",
    "for i, image_folder in enumerate([common_rust_images, healthy_images, leaf_spot_images, nothern_leaf_blight_images]):\n",
    "    for image in image_folder:\n",
    "        all_images.append(image)\n",
    "        all_labels.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b13a7cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_images), len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f639025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us extraxt KAZE features for all the images\n",
    "def extract_features_kaze_all():\n",
    "    \"\"\"Extracts kaze features for all the images in our dataset\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    X_train : numpy array\n",
    "        An array of shape (n, 4096) containing the kaze features used in training \n",
    "    X_test : numpy array\n",
    "        An array of shape (m, 4096) containing the kaze features used for testing\n",
    "    y_train : numpy array\n",
    "        An array of labels for the trainig set\n",
    "    y_test : numpy array\n",
    "        An array of labels for the test set\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for i, image in enumerate(all_images):\n",
    "        image_features = extract_features_kaze(image)\n",
    "        image_label = all_labels[i]\n",
    "        features.append(image_features)\n",
    "        labels.append(image_label)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6e84187",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = extract_features_kaze_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64f497c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 4096), (89,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62a649f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39, 4096), (39,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56085865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1275366 , 0.24601872, 0.19321055, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2503464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1095539 ,  0.12280111, -0.6038938 , ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4dce411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 1, 3, 1, 0, 1, 3, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae141304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3, 3, 3, 1, 1, 3, 3, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837791c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now these two, y_train and X_train can be fed into any classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffbb2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us extraxt ORB features for all the images\n",
    "def extract_features_orb_all():\n",
    "    \"\"\"Extracts orb features for all the images in our dataset\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    X_train : numpy array\n",
    "        An array of shape (n, 4096) containing the orb features used in training \n",
    "    X_test : numpy array\n",
    "        An array of shape (m, 4096) containing the orb features used for testing\n",
    "    y_train : numpy array\n",
    "        An array of labels for the trainig set\n",
    "    y_test : numpy array\n",
    "        An array of labels for the test set\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for i, image in enumerate(all_images):\n",
    "        try:\n",
    "            image_features = extract_features_orb(image)\n",
    "            image_label = all_labels[i]\n",
    "            features.append(image_features)\n",
    "            labels.append(image_label)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4191be66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87, 4096), (87,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = extract_features_orb_all()\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6138ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38, 4096), (38,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47cba486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us extraxt hog features for all the images\n",
    "def extract_features_hog_all():\n",
    "    \"\"\"Extracts hog features for all the images in our dataset\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    X_train : numpy array\n",
    "        An array of shape (n, 4096) containing the hog features used in training \n",
    "    X_test : numpy array\n",
    "        An array of shape (m, 4096) containing the hog features used for testing\n",
    "    y_train : numpy array\n",
    "        An array of labels for the trainig set\n",
    "    y_test : numpy array\n",
    "        An array of labels for the test set\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for i, image in enumerate(all_images):\n",
    "        image_features = extract_hog_features(image)\n",
    "        image_label = all_labels[i]\n",
    "        features.append(image_features)\n",
    "        labels.append(image_label)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbaabf5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 4096), (89,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = extract_features_hog_all()\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2a20afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39, 4096), (39,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a8a2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us extraxt SIFT features for all the images\n",
    "def extract_features_sift_all():\n",
    "    \"\"\"Extracts sift features for all the images in our dataset\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    X_train : numpy array\n",
    "        An array of shape (n, 4096) containing the kaze features used in training \n",
    "    X_test : numpy array\n",
    "        An array of shape (m, 4096) containing the kaze features used for testing\n",
    "    y_train : numpy array\n",
    "        An array of labels for the trainig set\n",
    "    y_test : numpy array\n",
    "        An array of labels for the test set\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for i, image in enumerate(all_images):\n",
    "        image_features = extract_features_sift(image)\n",
    "        image_label = all_labels[i]\n",
    "        features.append(image_features)\n",
    "        labels.append(image_label)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "352f39f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 4096), (89,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = extract_features_sift_all()\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bde3bc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39, 4096), (39,))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24954892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us extraxt BRIEF features for all the images\n",
    "def extract_features_brief_all():\n",
    "    \"\"\"Extracts sift features for all the images in our dataset\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    X_train : numpy array\n",
    "        An array of shape (n, 4096) containing the kaze features used in training \n",
    "    X_test : numpy array\n",
    "        An array of shape (m, 4096) containing the kaze features used for testing\n",
    "    y_train : numpy array\n",
    "        An array of labels for the trainig set\n",
    "    y_test : numpy array\n",
    "        An array of labels for the test set\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for i, image in enumerate(all_images):\n",
    "        image_features = extract_features_brief(image)\n",
    "        if image_features.shape[0]:\n",
    "            image_label = all_labels[i]\n",
    "            features.append(image_features)\n",
    "            labels.append(image_label)\n",
    "        else:\n",
    "            pass\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a9be845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77, 4096), (77,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = extract_features_brief_all()\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "755e0dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 4096), (34,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29a395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
