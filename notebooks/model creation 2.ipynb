{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for array manipulations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for image processing\n",
    "import cv2 \n",
    "#for displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "#to display images in this notebook, not in a separate window\n",
    "%matplotlib inline\n",
    "#to access system resources such as directories\n",
    "import os\n",
    "#This wilallow us to get the training time of each model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\USER\\\\Documents\\\\GitHub\\\\maize-disease-detection\\\\notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set our base directory. This should point to the location of the plant-diseases folder\n",
    "base_dir = 'C:\\\\Users\\\\USER\\\\Documents\\\\GitHub\\\\maize-disease-detection'\n",
    "data_folder = os.path.join(base_dir, 'data')\n",
    "maize_data_folder = os.path.join(data_folder, 'maize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function loads 32 images of a particular disease\n",
    "def get_32(disease):\n",
    "    '''\n",
    "    disease:\n",
    "        A string that could be common_rust, healthy, leaf_spot, nothern_leaf_blight\n",
    "    ........\n",
    "    disease_images:\n",
    "        A list of images for the selected disease\n",
    "    '''\n",
    "    #this list will contain the 20 images returned\n",
    "    disease_images = []\n",
    "    #path to the images\n",
    "    disease_images_path = os.path.join(maize_data_folder, disease)\n",
    "    for image_path in os.listdir(disease_images_path):\n",
    "        image_path = os.path.join(disease_images_path, image_path)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        disease_images.append(image)\n",
    "    return disease_images\n",
    "\n",
    "#This function will help us plot 10 images\n",
    "def plot_images(images, title):\n",
    "    '''\n",
    "    images: List\n",
    "        List of images\n",
    "    title: String\n",
    "        Title for each image i.e name of disease\n",
    "    '''\n",
    "    plt.figure(figsize=(15,6))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2,5, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(title)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "#This function generates ORB features\n",
    "def extract_features_orb(image, vector_size=32):\n",
    "    try:\n",
    "        feature_generator = cv2.ORB_create()\n",
    "        orb_keypoints = feature_generator.detect(image)\n",
    "        orb_keypoints = orb_keypoints[:32]\n",
    "        orb_keypoints, orb_descriptors = feature_generator.compute(image, orb_keypoints)\n",
    "        orb_descriptors = orb_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if orb_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            orb_descriptors = np.concatenate([orb_descriptors, np.zeros(needed_size - orb_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return orb_descriptors\n",
    "\n",
    "#This function generates KAZE features\n",
    "def extract_features_kaze(image, vector_size=32):\n",
    "    try:\n",
    "        feature_generator = cv2.KAZE_create()\n",
    "        kaze_keypoints = feature_generator.detect(image)\n",
    "        kaze_keypoints = kaze_keypoints[:32]\n",
    "        kaze_keypoints, kaze_descriptors = feature_generator.compute(image, kaze_keypoints)\n",
    "        kaze_descriptors = kaze_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if kaze_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            kaze_descriptors = np.concatenate([kaze_descriptors, np.zeros(needed_size - kaze_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return kaze_descriptors\n",
    "\n",
    "def extract_features_hog(image, feature_size=4096):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    features = hog.compute(image)\n",
    "    required_features = features[:feature_size].ravel()\n",
    "    return required_features\n",
    "\n",
    "#Let us extraxt KAZE features\n",
    "def extract_features(algorithm=0):\n",
    "    '''\n",
    "    Algorithm:\n",
    "        1 for ORB\n",
    "        0 for KAZE\n",
    "        2 for HOG\n",
    "    '''\n",
    "    #Now let us perform these steps for all the 32 images loaded\n",
    "    #This will contain all our images\n",
    "    all_images = []\n",
    "    #This will contain all our labels\n",
    "    all_labels = []\n",
    "    labels = ['common_rust', 'healthy', 'leaf_spot', 'nothern_leaf_blight']\n",
    "    for i, image_folder in enumerate([common_rust_images, healthy_images, leaf_spot_images, nothern_leaf_blight_images]):\n",
    "        for image in image_folder:\n",
    "            all_images.append(image)\n",
    "            all_labels.append(labels[i])\n",
    "    features, labels = [], []\n",
    "    for i, image in enumerate(all_images):\n",
    "        image_features = []\n",
    "        try:\n",
    "            if algorithm == 1:\n",
    "                image_features = extract_features_orb(image)\n",
    "            elif algorithm == 0:\n",
    "                image_features = extract_features_kaze(image)\n",
    "            else:\n",
    "                image_features = extract_features_hog(image)\n",
    "            image_label = all_labels[i]\n",
    "            features.append(image_features)\n",
    "            labels.append(image_label)\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#Let us extraxt KAZE features\n",
    "def extract_features2(algorithm=0):\n",
    "    '''\n",
    "    Algorithm:\n",
    "        1 for ORB\n",
    "        0 for KAZE\n",
    "        2 for HOG\n",
    "    '''\n",
    "    #Now let us perform these steps for all the 32 images loaded\n",
    "    #This will contain all our images\n",
    "    all_images = []\n",
    "    #This will contain all our labels\n",
    "    all_labels = []\n",
    "    labels = ['common_rust', 'healthy', 'leaf_spot', 'nothern_leaf_blight']\n",
    "    for i, image_folder in enumerate([common_rust_images, healthy_images, leaf_spot_images, nothern_leaf_blight_images]):\n",
    "        for image in image_folder:\n",
    "            all_images.append(image)\n",
    "            all_labels.append(labels[i])\n",
    "    features, labels = [], []\n",
    "    for i, image in enumerate(all_images):\n",
    "        image_features = []\n",
    "        try:\n",
    "            if algorithm == 1:\n",
    "                image_features = extract_features_orb(image)\n",
    "            elif algorithm == 0:\n",
    "                image_features = extract_features_kaze(image)\n",
    "            else:\n",
    "                image_features = extract_features_hog(image)\n",
    "            image_label = all_labels[i]\n",
    "            features.append(image_features)\n",
    "            labels.append(image_label)\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We have decided to choose these 6 models. They are easy to understand and work with.\n",
    "We will pick the five best for each data set, i,e five for HOG and five for KAZE.\n",
    "We dropped ORB since its perfomance was not very good. \n",
    "'''\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='auto'),\n",
    "    KNeighborsClassifier(),\n",
    "    LinearSVC(),\n",
    "    SVC(gamma='scale'),\n",
    "    DecisionTreeClassifier()\n",
    "]\n",
    "names = [\n",
    "    'Random Forest Classifier',\n",
    "    'Logistic Regression',\n",
    "    'K-Nearest Neighbors',\n",
    "    'Linear SVC',\n",
    "    'Support Vector Classifier',\n",
    "    'Decision Tree'\n",
    "]\n",
    "\n",
    "#This method gives us a rough idea about the accuracy of the base models and their raining times\n",
    "def train_base_models(X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    '''\n",
    "    model_accuracy = []\n",
    "    train_time = []\n",
    "    model_names = []\n",
    "    for i, classifier in enumerate(models):\n",
    "        try:\n",
    "            #Let us train the model and get the training time\n",
    "            start_time = time.time()\n",
    "            classifier.fit(X_train, y_train)\n",
    "            stop_time = time.time()\n",
    "            train_time.append(stop_time - start_time)\n",
    "            predictions = classifier.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, predictions)\n",
    "            model_accuracy.append(round(accuracy, 3))\n",
    "            model_names.append(names[i])\n",
    "            print(f'{names[i]}: {round(accuracy, 3)}')\n",
    "        except Exception as e:\n",
    "            print(f'Could not train {names[i]} because of {e}')\n",
    "    df = pd.DataFrame({'Model':model_names, 'Accuracy':model_accuracy, 'Train Time':train_time})\n",
    "    df = df.sort_values(by=['Accuracy'], ascending=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_rust_images = get_32('common_rust')\n",
    "healthy_images = get_32('healthy')\n",
    "leaf_spot_images = get_32('leaf_spot')\n",
    "nothern_leaf_blight_images = get_32('nothern_leaf_blight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These fatures are generated using KAZE\n",
    "kaze_X_train, kaze_X_test, kaze_y_train, kaze_y_test = extract_features() \n",
    "#These fatures are generated using HOG\n",
    "hog_X_train, hog_X_test, hog_y_train, hog_y_test = extract_features(algorithm=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: 0.667\n",
      "Logistic Regression: 0.564\n",
      "K-Nearest Neighbors: 0.59\n",
      "Linear SVC: 0.564\n",
      "Support Vector Classifier: 0.513\n",
      "Decision Tree: 0.564\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.219866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.021986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.388759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.087945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.049968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.052968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Train Time\n",
       "0   Random Forest Classifier     0.667    0.219866\n",
       "2        K-Nearest Neighbors     0.590    0.021986\n",
       "1        Logistic Regression     0.564    0.388759\n",
       "3                 Linear SVC     0.564    0.087945\n",
       "5              Decision Tree     0.564    0.049968\n",
       "4  Support Vector Classifier     0.513    0.052968"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaze = train_base_models(kaze_X_train, kaze_y_train, kaze_X_test, kaze_y_test)\n",
    "kaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The five best models are\n",
    "1. Random Forest\n",
    "2. K-Nearest Neighbors\n",
    "3. Logistic Regression\n",
    "4. Linear SVC\n",
    "5. Decision Tree\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: 0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\.conda\\envs\\computervision\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.59\n",
      "K-Nearest Neighbors: 0.615\n",
      "Linear SVC: 0.615\n",
      "Support Vector Classifier: 0.641\n",
      "Decision Tree: 0.615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Train Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Classifier</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.055964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.022987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.861413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.102062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.421176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.277828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy  Train Time\n",
       "4  Support Vector Classifier     0.641    0.055964\n",
       "2        K-Nearest Neighbors     0.615    0.022987\n",
       "3                 Linear SVC     0.615    0.861413\n",
       "5              Decision Tree     0.615    0.102062\n",
       "1        Logistic Regression     0.590    0.421176\n",
       "0   Random Forest Classifier     0.513    0.277828"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog = train_base_models(hog_X_train, hog_y_train, hog_X_test, hog_y_test)\n",
    "hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The five best models are:\n",
    "1. Support Vector classifier\n",
    "2. K-Nearest Neighbors\n",
    "3. Linear SVC\n",
    "4. Decision Tree\n",
    "5. Logistic Regression\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here we work on the five best models from KAZE\n",
    "'''\n",
    "random_forest = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "logistic_regression = LogisticRegression()\n",
    "linear_svc = LinearSVC()\n",
    "decision_tree = DecisionTreeClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
