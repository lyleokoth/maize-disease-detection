{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for array manipulations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for image processing\n",
    "import cv2 \n",
    "#for displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "#to display images in this notebook, not in a separate window\n",
    "%matplotlib inline\n",
    "#to access system resources such as directories\n",
    "import os\n",
    "#This wilallow us to get the training time of each model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\USER\\\\Documents\\\\GitHub\\\\maize-disease-detection\\\\notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set our base directory. This should point to the location of the plant-diseases folder\n",
    "base_dir = 'C:\\\\Users\\\\USER\\\\Documents\\\\GitHub\\\\maize-disease-detection'\n",
    "data_folder = os.path.join(base_dir, 'data')\n",
    "maize_data_folder = os.path.join(data_folder, 'maize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function loads 32 images of a particular disease\n",
    "def get_32(disease):\n",
    "    '''\n",
    "    disease:\n",
    "        A string that could be common_rust, healthy, leaf_spot, nothern_leaf_blight\n",
    "    ........\n",
    "    disease_images:\n",
    "        A list of images for the selected disease\n",
    "    '''\n",
    "    #this list will contain the 20 images returned\n",
    "    disease_images = []\n",
    "    #path to the images\n",
    "    disease_images_path = os.path.join(maize_data_folder, disease)\n",
    "    for image_path in os.listdir(disease_images_path):\n",
    "        image_path = os.path.join(disease_images_path, image_path)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        disease_images.append(image)\n",
    "    return disease_images\n",
    "\n",
    "#This function will help us plot 10 images\n",
    "def plot_images(images, title):\n",
    "    '''\n",
    "    images: List\n",
    "        List of images\n",
    "    title: String\n",
    "        Title for each image i.e name of disease\n",
    "    '''\n",
    "    plt.figure(figsize=(15,6))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2,5, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(title)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "#This function generates ORB features\n",
    "def extract_features_orb(image, vector_size=32):\n",
    "    try:\n",
    "        feature_generator = cv2.ORB_create()\n",
    "        orb_keypoints = feature_generator.detect(image)\n",
    "        orb_keypoints = orb_keypoints[:32]\n",
    "        orb_keypoints, orb_descriptors = feature_generator.compute(image, orb_keypoints)\n",
    "        orb_descriptors = orb_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if orb_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            orb_descriptors = np.concatenate([orb_descriptors, np.zeros(needed_size - orb_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return orb_descriptors\n",
    "\n",
    "#This function generates KAZE features\n",
    "def extract_features_kaze(image, vector_size=32):\n",
    "    try:\n",
    "        feature_generator = cv2.KAZE_create()\n",
    "        kaze_keypoints = feature_generator.detect(image)\n",
    "        kaze_keypoints = kaze_keypoints[:32]\n",
    "        kaze_keypoints, kaze_descriptors = feature_generator.compute(image, kaze_keypoints)\n",
    "        kaze_descriptors = kaze_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if kaze_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            kaze_descriptors = np.concatenate([kaze_descriptors, np.zeros(needed_size - kaze_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return kaze_descriptors\n",
    "\n",
    "def extract_features_hog(image, feature_size=4096):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    features = hog.compute(image)\n",
    "    required_features = features[:feature_size].ravel()\n",
    "    return required_features\n",
    "\n",
    "#Let us extraxt KAZE features\n",
    "def extract_features(algorithm=0):\n",
    "    '''\n",
    "    Algorithm:\n",
    "        1 for ORB\n",
    "        0 for KAZE\n",
    "        2 for HOG\n",
    "    '''\n",
    "    #Now let us perform these steps for all the 32 images loaded\n",
    "    #This will contain all our images\n",
    "    all_images = []\n",
    "    #This will contain all our labels\n",
    "    all_labels = []\n",
    "    labels = ['common_rust', 'healthy', 'leaf_spot', 'nothern_leaf_blight']\n",
    "    for i, image_folder in enumerate([common_rust_images, healthy_images, leaf_spot_images, nothern_leaf_blight_images]):\n",
    "        for image in image_folder:\n",
    "            all_images.append(image)\n",
    "            all_labels.append(labels[i])\n",
    "    features, labels = [], []\n",
    "    for i, image in enumerate(all_images):\n",
    "        image_features = []\n",
    "        try:\n",
    "            if algorithm == 1:\n",
    "                image_features = extract_features_orb(image)\n",
    "            elif algorithm == 0:\n",
    "                image_features = extract_features_kaze(image)\n",
    "            else:\n",
    "                image_features = extract_features_hog(image)\n",
    "            image_label = all_labels[i]\n",
    "            features.append(image_features)\n",
    "            labels.append(image_label)\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We have decided to choose these 6 models. They are easy to understand and work with.\n",
    "We will pick the five best for each data set, i,e five for HOG and five for KAZE.\n",
    "We dropped ORB since its perfomance was not very good. \n",
    "'''\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='auto'),\n",
    "    KNeighborsClassifier(),\n",
    "    LinearSVC(),\n",
    "    SVC(gamma='scale'),\n",
    "    DecisionTreeClassifier()\n",
    "]\n",
    "names = [\n",
    "    'Random Forest Classifier',\n",
    "    'Logistic Regression',\n",
    "    'K-Nearest Neighbors',\n",
    "    'Linear SVC',\n",
    "    'Support Vector Classifier',\n",
    "    'Decision Tree'\n",
    "]\n",
    "\n",
    "#This method gives us a rough idea about the accuracy of the base models and their raining times\n",
    "def train_base_models(X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    '''\n",
    "    model_accuracy = []\n",
    "    train_time = []\n",
    "    model_names = []\n",
    "    for i, classifier in enumerate(models):\n",
    "        try:\n",
    "            #Let us train the model and get the training time\n",
    "            start_time = time.time()\n",
    "            classifier.fit(X_train, y_train)\n",
    "            stop_time = time.time()\n",
    "            train_time.append(stop_time - start_time)\n",
    "            predictions = classifier.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, predictions)\n",
    "            model_accuracy.append(round(accuracy, 3))\n",
    "            model_names.append(names[i])\n",
    "            print(f'{names[i]}: {round(accuracy, 3)}')\n",
    "        except Exception as e:\n",
    "            print(f'Could not train {names[i]} because of {e}')\n",
    "    df = pd.DataFrame({'Model':model_names, 'Accuracy':model_accuracy, 'Train Time':train_time})\n",
    "    df = df.sort_values(by=['Accuracy'], ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
