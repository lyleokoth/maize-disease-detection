{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb3b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are imports for models and utilities for working with models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "504429e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for array manipulations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#for image processing\n",
    "import cv2 \n",
    "#for displaying images\n",
    "import matplotlib.pyplot as plt\n",
    "#to display images in this notebook, not in a separate window\n",
    "%matplotlib inline\n",
    "#to access system resources such as directories\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abfab211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set this to point to the project root; all paths will be relative to this one\n",
    "project_dir = '/home/lyle/notebooks/maize-disease-detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3413693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_directories(project_dir=project_dir):\n",
    "    \"\"\"Sets up the paths to important direcoties\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    project_dir : string; default is the current working directory\n",
    "        The path to the project root i.e '/home/lyle/tutorials/AI/scikit-learn/maize-disease-detection/'\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    base_dir : string\n",
    "        The project directory path\n",
    "    data_folder : string\n",
    "        The data subfolder path\n",
    "    maize_data_folder : \n",
    "        The path to the subdirectory containing the maize images\n",
    "        \n",
    "    example usage\n",
    "    -------------\n",
    "    base_dir, data_folder, maize_data_folder = set_up_directories()\n",
    "    \"\"\"\n",
    "    \n",
    "    #set our base directory. This should point to the location of the plant-diseases folder\n",
    "    base_dir = project_dir\n",
    "    #set the path to our data folder\n",
    "    data_folder = os.path.join(base_dir, 'data')\n",
    "    #set the path to the maize folder and list the various categories available\n",
    "    maize_data_folder = os.path.join(data_folder, 'maize')\n",
    "\n",
    "    return base_dir, data_folder, maize_data_folder\n",
    "\n",
    "def get_32(disease):\n",
    "    \"\"\"Loads 32 images for a given maize disease\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    disease: string\n",
    "        A string that could be common_rust, healthy, leaf_spot, nothern_leaf_blight\n",
    "    returns\n",
    "    -------\n",
    "    disease_images: list\n",
    "        A list of images for the selected disease\n",
    "    \"\"\"\n",
    "    \n",
    "    #this list will contain the 20 images returned\n",
    "    disease_images = []\n",
    "    #path to the images\n",
    "    disease_images_path = os.path.join(maize_data_folder, disease)\n",
    "    for image_path in os.listdir(disease_images_path):\n",
    "        image_path = os.path.join(disease_images_path, image_path)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        disease_images.append(image)\n",
    "    return disease_images\n",
    "\n",
    "#This function will help us plot 10 images\n",
    "def plot_images(images, title):\n",
    "    \"\"\"Plots 10 images of a particular disease category\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    images: list\n",
    "        List of images(each image is an array)\n",
    "    title: string\n",
    "        Title for each image i.e name of disease\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(12,8))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2,5, i+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(title)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "#This function allows us to resize images\n",
    "def resize(image, new_size=(600,600)):\n",
    "    \"\"\"Resize the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image to be resized\n",
    "    new_size : tuple\n",
    "        The new image size\n",
    "    returns\n",
    "    -------\n",
    "    resized_image : numpy arra\n",
    "        The resized image\n",
    "    \"\"\"\n",
    "    \n",
    "    resized_image = cv2.resize(image, new_size)\n",
    "    return resized_image\n",
    "\n",
    "#This function generates ORB features\n",
    "def extract_features_orb(image, vector_size=32):\n",
    "    \"\"\"Extracts orb features for the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    returns\n",
    "    -------\n",
    "        orb_decriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feature_generator = cv2.ORB_create()\n",
    "        orb_keypoints = feature_generator.detect(image)\n",
    "        orb_keypoints = orb_keypoints[:32]\n",
    "        orb_keypoints, orb_descriptors = feature_generator.compute(image, orb_keypoints)\n",
    "        orb_descriptors = orb_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if orb_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            orb_descriptors = np.concatenate([orb_descriptors, np.zeros(needed_size - orb_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return orb_descriptors\n",
    "\n",
    "#This function generates KAZE features\n",
    "def extract_features_kaze(image, vector_size=32):\n",
    "    \"\"\"Extracts kaze features for the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    returns\n",
    "    -------\n",
    "        kaze_descriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feature_generator = cv2.KAZE_create()\n",
    "        kaze_keypoints = feature_generator.detect(image)\n",
    "        kaze_keypoints = kaze_keypoints[:32]\n",
    "        kaze_keypoints, kaze_descriptors = feature_generator.compute(image, kaze_keypoints)\n",
    "        kaze_descriptors = kaze_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if kaze_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            kaze_descriptors = np.concatenate([kaze_descriptors, np.zeros(needed_size - kaze_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return kaze_descriptors\n",
    "\n",
    "def extract_features_hog(image, feature_size=4096):\n",
    "    \"\"\"Extracts hog features for the image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    feature_size : int\n",
    "        The number of features to generate\n",
    "    returns\n",
    "    -------\n",
    "        hog_features : numpy array \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    features = hog.compute(image)\n",
    "    required_features = features[:feature_size].ravel()\n",
    "    return required_features\n",
    "\n",
    "#This function generates SIFT features\n",
    "def extract_features_sift(image, vector_size=32):\n",
    "    \"\"\"Extracts sift features for the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    returns\n",
    "    -------\n",
    "        sift_descriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        feature_generator = cv2.SIFT_create()\n",
    "        sift_keypoints = feature_generator.detect(image)\n",
    "        sift_keypoints = sift_keypoints[:32]\n",
    "        sift_keypoints, sift_descriptors = feature_generator.compute(image, sift_keypoints)\n",
    "        sift_descriptors = sift_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if sift_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            sift_descriptors = np.concatenate([sift_descriptors, np.zeros(needed_size - sift_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return sift_descriptors\n",
    "\n",
    "#This function generates SURF features\n",
    "def extract_features_surf(image, vector_size=32):\n",
    "    \"\"\"Extracts surf features for the given image\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    returns\n",
    "    -------\n",
    "        surf_descriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initiate FAST detector\n",
    "        star = cv2.xfeatures2d.StarDetector_create()\n",
    "        surf_keypoints = feature_generator.detect(image)\n",
    "        surf_keypoints = surf_keypoints[:32]\n",
    "        surf_keypoints, surf_descriptors = feature_generator.compute(image, surf_keypoints)\n",
    "        surf_descriptors = surf_descriptors.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if surf_descriptors.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            sift_descriptors = np.concatenate([surf_descriptors, np.zeros(needed_size - surf_descriptors.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None\n",
    "    return surf_descriptors\n",
    "\n",
    "#This function generates BRIEF features\n",
    "def extract_features_brief(image, vector_size=32, algorithm=\"star\"):\n",
    "    \"\"\"Extracts features for the given image using BRIEF\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    image : numpy array\n",
    "        The image whose features are to be extracted\n",
    "    vector_size : int\n",
    "        The number of keypoints to use\n",
    "    algorithm : string\n",
    "        The algorithm to use; can be star or fast\n",
    "    returns\n",
    "    -------\n",
    "        brief_descriptors : \n",
    "        \n",
    "    raises\n",
    "    ------\n",
    "    cv2.error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        alg = cv2.xfeatures2d.StarDetector_create()\n",
    "        if algorithm == \"fast\":\n",
    "            alg = cv2.FastFeatureDetector_create()\n",
    "        brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "        \n",
    "        kp = alg.detect(image, None)\n",
    "        kp = kp[:32]\n",
    "        kp, des = brief.compute(image, kp)\n",
    "        des = des.flatten()\n",
    "        #The descriptor vector size is 128\n",
    "        needed_size = (vector_size*128)\n",
    "        if des.size < needed_size:\n",
    "            #If we have less than 32 keypoints, add zeros to the end of our vector\n",
    "            des = np.concatenate([des, np.zeros(needed_size - des.size)])\n",
    "    except cv2.error as e:\n",
    "        print(f'Error: {e}')\n",
    "        return np.array([])\n",
    "    except AttributeError:\n",
    "        return np.array([])\n",
    "    return des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b4fe833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directories set up\n",
    "base_dir, data_folder, maize_data_folder = set_up_directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c472affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_images():\n",
    "    \"\"\"Loads all the images in our maize data folder\n",
    "    \n",
    "    returns\n",
    "    -------\n",
    "    all_images : list\n",
    "        List of images\n",
    "    all_labels : list\n",
    "        List of corresponding image labels\n",
    "    \"\"\"\n",
    "    \n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    labels = ['common_rust', 'healthy', 'leaf_spot', 'nothern_leaf_blight']\n",
    "    common_rust_images = get_32('common_rust')\n",
    "    healthy_images = get_32('healthy')\n",
    "    leaf_spot_images = get_32('leaf_spot')\n",
    "    nothern_leaf_blight_images = get_32('nothern_leaf_blight')\n",
    "    \n",
    "    for i, image_folder in enumerate([common_rust_images, healthy_images, leaf_spot_images, nothern_leaf_blight_images]):\n",
    "        for image in image_folder:\n",
    "            all_images.append(image)\n",
    "            all_labels.append(labels[i])\n",
    "            \n",
    "    return all_images, all_labels\n",
    "\n",
    "#Function to extract features using a particular algorithm\n",
    "def extract_features(algorithm=0):\n",
    "    \"\"\"Extract features for all images in our dataset\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    algorithm : int\n",
    "        An integer that could be 0, 1, 2, 3, 4\n",
    "        0 for KAZE\n",
    "        1 for ORB\n",
    "        2 for HOG\n",
    "        3 for SIFT\n",
    "        4 for BRIEF\n",
    "    return\n",
    "    ------\n",
    "    X_train : numpy array\n",
    "        An array of shape (n, 4096) containing the features used in training \n",
    "    X_test : numpy array\n",
    "        An array of shape (m, 4096) containing the features used for testing\n",
    "    y_train : numpy array\n",
    "        An array of labels for the trainig set\n",
    "    y_test : numpy array\n",
    "        An array of labels for the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    all_images, all_labels = load_all_images()\n",
    "    \n",
    "    features, labels = [], []\n",
    "    \n",
    "    for i, image in enumerate(all_images):\n",
    "        image_features = []\n",
    "        try:\n",
    "            if algorithm == 0:\n",
    "                image_features = extract_features_kaze(image)\n",
    "            elif algorithm == 1:\n",
    "                image_features = extract_features_orb(image)\n",
    "            elif algorithm == 2:\n",
    "                image_features = extract_features_hog(image)\n",
    "            elif algorithm == 3:\n",
    "                image_features = extract_features_sift(image)\n",
    "            elif algorithm == 4:\n",
    "                image_features = extract_features_brief(image)\n",
    "            if image_features.shape[0]:\n",
    "                image_label = all_labels[i]\n",
    "                features.append(image_features)\n",
    "                labels.append(image_label)\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba5e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = extract_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528a377a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 4096), (89,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83d9097f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39, 4096), (39,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5a3adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100),\n",
    "    LogisticRegression(solver='lbfgs', multi_class='auto'),\n",
    "    AdaBoostClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    BernoulliNB(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    MLPClassifier(),\n",
    "    LinearSVC(),\n",
    "    SVC(gamma='scale')\n",
    "]\n",
    "names = [\n",
    "    'Random Forest',\n",
    "    'Logistic Regression',\n",
    "    'AdaBoost',\n",
    "    'Bagging',\n",
    "    'Gradient Boosting',\n",
    "    'Bernoulli NB',\n",
    "    'Gaussian NB',\n",
    "    'K-Nearest Neighbors',\n",
    "    'Neural Network',\n",
    "    'Linear SVC',\n",
    "    'Support Vector Machine'\n",
    "]\n",
    "\n",
    "def train_base_models(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Used to train the above given list of models\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    X_train : numpy array\n",
    "        The training set values\n",
    "    y_train : numpy array\n",
    "        The training set labels\n",
    "    X_test : numpy array\n",
    "        The testing set values\n",
    "    y_test : numpy array\n",
    "        The testing set labels\n",
    "    returns\n",
    "    -------\n",
    "    df : Pandas DataFrame\n",
    "        A DataFrame showing model accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    model_accuracy = []\n",
    "    model_names = []\n",
    "    \n",
    "    for i, classifier in enumerate(models):\n",
    "        try:\n",
    "            classifier.fit(X_train, y_train)\n",
    "            predictions = classifier.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, predictions)\n",
    "            model_accuracy.append(round(accuracy, 3))\n",
    "            model_names.append(names[i])\n",
    "            print(f'{names[i]}: {round(accuracy, 3)}')\n",
    "        except Exception as e:\n",
    "            print(f'Could not train {names[i]} because of {e}')\n",
    "            \n",
    "    df = pd.DataFrame({'Model':model_names, 'Accuracy':model_accuracy})\n",
    "    df = df.sort_values(by=['Accuracy'], ascending=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51ffc34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.718\n",
      "Logistic Regression: 0.692\n",
      "AdaBoost: 0.615\n",
      "Bagging: 0.744\n",
      "Gradient Boosting: 0.564\n",
      "Bernoulli NB: 0.692\n",
      "Gaussian NB: 0.615\n",
      "K-Nearest Neighbors: 0.718\n",
      "Neural Network: 0.718\n",
      "Linear SVC: 0.641\n",
      "Support Vector Machine: 0.667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bernoulli NB</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>0.615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy\n",
       "3                  Bagging     0.744\n",
       "0            Random Forest     0.718\n",
       "7      K-Nearest Neighbors     0.718\n",
       "8           Neural Network     0.718\n",
       "1      Logistic Regression     0.692\n",
       "5             Bernoulli NB     0.692\n",
       "10  Support Vector Machine     0.667\n",
       "9               Linear SVC     0.641\n",
       "2                 AdaBoost     0.615\n",
       "6              Gaussian NB     0.615\n",
       "4        Gradient Boosting     0.564"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model perfomance on features generated using KAZE\n",
    "df = train_base_models(X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e7ee94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'flatten'\n",
      "'NoneType' object has no attribute 'flatten'\n",
      "'NoneType' object has no attribute 'flatten'\n"
     ]
    }
   ],
   "source": [
    "#These features are gnerated using ORB\n",
    "X_train2, X_test2, y_train2, y_test2 = extract_features(algorithm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "227ea9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87, 4096), (87,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape, y_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37b673d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38, 4096), (38,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2.shape, y_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a76600a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.447\n",
      "Logistic Regression: 0.5\n",
      "AdaBoost: 0.289\n",
      "Bagging: 0.342\n",
      "Gradient Boosting: 0.342\n",
      "Bernoulli NB: 0.474\n",
      "Gaussian NB: 0.5\n",
      "K-Nearest Neighbors: 0.447\n",
      "Neural Network: 0.579\n",
      "Linear SVC: 0.605\n",
      "Support Vector Machine: 0.395\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bernoulli NB</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy\n",
       "9               Linear SVC     0.605\n",
       "8           Neural Network     0.579\n",
       "1      Logistic Regression     0.500\n",
       "6              Gaussian NB     0.500\n",
       "5             Bernoulli NB     0.474\n",
       "0            Random Forest     0.447\n",
       "7      K-Nearest Neighbors     0.447\n",
       "10  Support Vector Machine     0.395\n",
       "3                  Bagging     0.342\n",
       "4        Gradient Boosting     0.342\n",
       "2                 AdaBoost     0.289"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model perfomance on features generated using ORB\n",
    "df2 = train_base_models(X_train2, y_train2, X_test2, y_test2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8561737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The base models perform so badly with ORB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a0b3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These fatures are generated using HOG\n",
    "X_train3, X_test3, y_train3, y_test3 = extract_features(algorithm=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a008fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 4096), (89,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3.shape, y_train3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91fceed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39, 4096), (39,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test3.shape, y_test3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e03a3bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyle/notebooks/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.667\n",
      "AdaBoost: 0.359\n",
      "Bagging: 0.538\n",
      "Gradient Boosting: 0.538\n",
      "Bernoulli NB: 0.487\n",
      "Gaussian NB: 0.538\n",
      "K-Nearest Neighbors: 0.487\n",
      "Neural Network: 0.59\n",
      "Linear SVC: 0.692\n",
      "Support Vector Machine: 0.59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bernoulli NB</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy\n",
       "9               Linear SVC     0.692\n",
       "0            Random Forest     0.667\n",
       "1      Logistic Regression     0.667\n",
       "8           Neural Network     0.590\n",
       "10  Support Vector Machine     0.590\n",
       "3                  Bagging     0.538\n",
       "4        Gradient Boosting     0.538\n",
       "6              Gaussian NB     0.538\n",
       "5             Bernoulli NB     0.487\n",
       "7      K-Nearest Neighbors     0.487\n",
       "2                 AdaBoost     0.359"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model perfomance on features generated using HOG\n",
    "df3 = train_base_models(X_train3, y_train3, X_test3, y_test3)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8c05e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These fatures are generated using SIFT\n",
    "X_train4, X_test4, y_train4, y_test4 = extract_features(algorithm=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46890605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89, 4096), (89,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train4.shape, y_train4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeea7542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39, 4096), (39,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test4.shape, y_test4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89ae45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.538\n",
      "Logistic Regression: 0.59\n",
      "AdaBoost: 0.436\n",
      "Bagging: 0.513\n",
      "Gradient Boosting: 0.436\n",
      "Bernoulli NB: 0.641\n",
      "Gaussian NB: 0.436\n",
      "K-Nearest Neighbors: 0.231\n",
      "Neural Network: 0.436\n",
      "Linear SVC: 0.641\n",
      "Support Vector Machine: 0.359\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bernoulli NB</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy\n",
       "5             Bernoulli NB     0.641\n",
       "9               Linear SVC     0.641\n",
       "1      Logistic Regression     0.590\n",
       "0            Random Forest     0.538\n",
       "3                  Bagging     0.513\n",
       "2                 AdaBoost     0.436\n",
       "4        Gradient Boosting     0.436\n",
       "6              Gaussian NB     0.436\n",
       "8           Neural Network     0.436\n",
       "10  Support Vector Machine     0.359\n",
       "7      K-Nearest Neighbors     0.231"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model perfomance on features generated using SIFT\n",
    "df4 = train_base_models(X_train4, y_train4, X_test4, y_test4)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3871aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These fatures are generated using BRIEF\n",
    "X_train5, X_test5, y_train5, y_test5 = extract_features(algorithm=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec0946aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77, 4096), (77,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train5.shape, y_train5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a2e28e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34, 4096), (34,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test5.shape, y_test5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a19c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: 0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyle/notebooks/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.441\n",
      "AdaBoost: 0.324\n",
      "Bagging: 0.412\n",
      "Gradient Boosting: 0.471\n",
      "Bernoulli NB: 0.265\n",
      "Gaussian NB: 0.529\n",
      "K-Nearest Neighbors: 0.324\n",
      "Neural Network: 0.471\n",
      "Linear SVC: 0.324\n",
      "Support Vector Machine: 0.382\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gaussian NB</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bernoulli NB</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy\n",
       "6              Gaussian NB     0.529\n",
       "4        Gradient Boosting     0.471\n",
       "8           Neural Network     0.471\n",
       "1      Logistic Regression     0.441\n",
       "0            Random Forest     0.412\n",
       "3                  Bagging     0.412\n",
       "10  Support Vector Machine     0.382\n",
       "2                 AdaBoost     0.324\n",
       "7      K-Nearest Neighbors     0.324\n",
       "9               Linear SVC     0.324\n",
       "5             Bernoulli NB     0.265"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model perfomance on features generated using BRIEF\n",
    "df5 = train_base_models(X_train5, y_train5, X_test5, y_test5)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb639fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
